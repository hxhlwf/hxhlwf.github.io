---
layout: post
category: "nlp"
title: "2017年度10大值得读的nlp方面的paper"
tags: [2017, nlp, ]
---

目录

<!-- TOC -->

- [1. Attention Is All You Need](#1-attention-is-all-you-need)
- [2. Reinforcement Learning for Relation Classification from Noisy Data](#2-reinforcement-learning-for-relation-classification-from-noisy-data)
- [3. Convolutional Sequence to Sequence Learning](#3-convolutional-sequence-to-sequence-learning)
- [4. Zero-Shot Relation Extraction via Reading Comprehension](#4-zero-shot-relation-extraction-via-reading-comprehension)
- [5. IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models](#5-irgan-a-minimax-game-for-unifying-generative-and-discriminative-information-retrieval-models)
- [6. Neural Relation Extraction with Selective Attention over Instances](#6-neural-relation-extraction-with-selective-attention-over-instances)
- [7. Unsupervised Neural Machine Translation](#7-unsupervised-neural-machine-translation)
- [8. Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme](#8-joint-extraction-of-entities-and-relations-based-on-a-novel-tagging-scheme)
- [9. A Structured Self-attentive Sentence Embedding](#9-a-structured-self-attentive-sentence-embedding)
- [10. Dialogue Learning With Human-In-The-Loop](#10-dialogue-learning-with-human-in-the-loop)

<!-- /TOC -->

参考 [2017年度最值得读的AI论文 \| NLP篇 · 评选结果公布](https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247487348&idx=1&sn=8ee8bf57418342a419fe73829cb14e75&chksm=96e9d0f4a19e59e288dcb105bd90b1e13f419ee7268ac69eba7cd6dac12e2e64aa84c56e5c07&mpshare=1&scene=1&srcid=0130mjKCPyhYcXPqH6S7PcmU&pass_ticket=ZxuI7pnWcDwwNYf9OiipCrRncMzWnmWp6BRC9ytl30FalvvjUOKKM1gQYP2e0qkU#rd)

## 1. Attention Is All You Need

## 2. Reinforcement Learning for Relation Classification from Noisy Data

## 3. Convolutional Sequence to Sequence Learning

## 4. Zero-Shot Relation Extraction via Reading Comprehension

## 5. IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models

## 6. Neural Relation Extraction with Selective Attention over Instances

## 7. Unsupervised Neural Machine Translation

## 8. Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme

## 9. A Structured Self-attentive Sentence Embedding

## 10. Dialogue Learning With Human-In-The-Loop

